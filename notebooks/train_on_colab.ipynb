{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Voice Conversion - Training\n",
        "\n",
        "This notebook trains the voice conversion system on Google Colab.\n",
        "\n",
        "**Steps:**\n",
        "1. Mount Google Drive\n",
        "2. Install dependencies\n",
        "3. Download VCTK dataset\n",
        "4. Train speaker encoder\n",
        "5. Train voice conversion model\n",
        "\n",
        "**Expected Time:** ~20-24 hours total (with free Colab GPU)"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository (or upload your code to Drive)\n",
        "!git clone https://github.com/jahuytee/Neural-Voice-Conversion-via-Learned-Speaker-Embeddings-and-Time-Frequency-Speech-Representations.git\n",
        "%cd Neural-Voice-Conversion-via-Learned-Speaker-Embeddings-and-Time-Frequency-Speech-Representations"
      ],
      "metadata": {
        "id": "clone_repo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchaudio\n",
        "!pip install -q numpy scipy librosa\n",
        "!pip install -q pyworld\n",
        "!pip install -q tqdm matplotlib tabulate\n",
        "!pip install -q soundfile\n",
        "\n",
        "print(\"âœ… Dependencies installed!\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download VCTK Dataset"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download VCTK corpus (~11 GB, takes ~15-20 minutes)\n",
        "!python scripts/download_vctk.py --output /content/drive/MyDrive/vctk_data\n",
        "\n",
        "# OR if download fails, use manual method:\n",
        "# !wget https://datashare.ed.ac.uk/bitstream/handle/10283/3443/VCTK-Corpus-0.92.zip\n",
        "# !unzip VCTK-Corpus-0.92.zip -d /content/drive/MyDrive/vctk_data"
      ],
      "metadata": {
        "id": "download_vctk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Speaker Encoder\n",
        "\n",
        "**Time:** ~8 hours on T4 GPU  \n",
        "**Note:** Save checkpoints to Drive to resume if session times out"
      ],
      "metadata": {
        "id": "train_speaker_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train speaker encoder\n",
        "!python scripts/train_speaker_encoder.py \\\n",
        "  --data /content/drive/MyDrive/vctk_data/vctk/wav48_silence_trimmed \\\n",
        "  --output /content/drive/MyDrive/checkpoints/speaker_encoder \\\n",
        "  --epochs 100 \\\n",
        "  --batch-size 16 \\\n",
        "  --lr 2e-4 \\\n",
        "  --device cuda\n",
        "\n",
        "# To resume from checkpoint:\n",
        "# Add: --resume /content/drive/MyDrive/checkpoints/speaker_encoder/speaker_encoder_epoch_50.pt"
      ],
      "metadata": {
        "id": "train_speaker"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Voice Conversion Model\n",
        "\n",
        "**Time:** ~12-18 hours on T4 GPU  \n",
        "**Requires:** Trained speaker encoder from previous step"
      ],
      "metadata": {
        "id": "train_vc_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train voice conversion model\n",
        "!python scripts/train_vc.py \\\n",
        "  --data /content/drive/MyDrive/vctk_data/vctk/wav48_silence_trimmed \\\n",
        "  --speaker-encoder /content/drive/MyDrive/checkpoints/speaker_encoder/speaker_encoder_epoch_100.pt \\\n",
        "  --output /content/drive/MyDrive/checkpoints/voice_conversion \\\n",
        "  --epochs 200 \\\n",
        "  --batch-size 8 \\\n",
        "  --lr 1e-4 \\\n",
        "  --device cuda\n",
        "\n",
        "# To resume:\n",
        "# Add: --resume /content/drive/MyDrive/checkpoints/voice_conversion/voice_conversion_epoch_100.pt"
      ],
      "metadata": {
        "id": "train_vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Voice Conversion"
      ],
      "metadata": {
        "id": "test_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract a speaker embedding from VCTK\n",
        "!python scripts/extract_speaker.py \\\n",
        "  --audio \"/content/drive/MyDrive/vctk_data/vctk/wav48_silence_trimmed/p225/*.flac\" \\\n",
        "  --output /content/drive/MyDrive/embeddings/p225.pt \\\n",
        "  --speaker-encoder /content/drive/MyDrive/checkpoints/speaker_encoder/speaker_encoder_epoch_100.pt \\\n",
        "  --vc-model /content/drive/MyDrive/checkpoints/voice_conversion/voice_conversion_epoch_200.pt"
      ],
      "metadata": {
        "id": "extract_speaker"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test conversion (use your own audio or another VCTK speaker)\n",
        "!python convert.py \\\n",
        "  --input /content/drive/MyDrive/my_test_audio.wav \\\n",
        "  --target /content/drive/MyDrive/embeddings/p225.pt \\\n",
        "  --output /content/drive/MyDrive/converted_output.wav \\\n",
        "  --speaker-encoder /content/drive/MyDrive/checkpoints/speaker_encoder/speaker_encoder_epoch_100.pt \\\n",
        "  --vc-model /content/drive/MyDrive/checkpoints/voice_conversion/voice_conversion_epoch_200.pt"
      ],
      "metadata": {
        "id": "test_conversion"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play converted audio\n",
        "from IPython.display import Audio\n",
        "Audio('/content/drive/MyDrive/converted_output.wav')"
      ],
      "metadata": {
        "id": "play_audio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Trained Models\n",
        "\n",
        "After training completes, download checkpoints to use locally!"
      ],
      "metadata": {
        "id": "download_models_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All checkpoints are saved in:\n",
        "# /content/drive/MyDrive/checkpoints/\n",
        "\n",
        "# You can access them anytime from your Google Drive!\n",
        "!ls -lh /content/drive/MyDrive/checkpoints/speaker_encoder/\n",
        "!ls -lh /content/drive/MyDrive/checkpoints/voice_conversion/"
      ],
      "metadata": {
        "id": "list_checkpoints"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
